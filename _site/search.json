[
  {
    "objectID": "Package.html",
    "href": "Package.html",
    "title": "The package",
    "section": "",
    "text": "Installation\n\nlibrary(devtools) # Tools to Make Developing R Packages Easier \ndevtools::install_github(\"Watjoa/CaviR\")\n\n\n\nCorrelations\nUsing the coRtable function to have a clear, informative correlation table with descriptions\n\ncoRtable(data[,c(\"Extra\",\"Agree\",\"Con\",\"Neur\",\"Open\")])\n\n\n MSD1.2.3.4.5.1. Extra3.580.522. Agree3.660.53.22*3. Con3.430.54.06.42***4. Neur2.760.8.06-.19-.28**5. Open3.410.58.44***.22*.27**.04Note. *** p &lt;.001, ** p &lt;. 01, * p &lt; .05\n\n\nor use the multicoR function to have a correlation table for within-group and between-group level. Descriptives are based on the between-group level.\n\nmulticoR(datamultilevel[, c(\n  \"ID\",\"Integration\",\"Suppression\",\"Dysregulation\")])\n\n\n MSDICC1.2.3.1. Integration3.290.660.64-.08***.23***2. Suppression2.320.760.63-.25***.15***3. Dysregulation2.260.730.59.18***.35***Note. *** p &lt;.001, ** p &lt;. 01, * p &lt; .05\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn R, you can select the whole output (CTRL+A or CMD+A) and paste the output in excel to provide further modifications.\n\n\n\n\n(M)ANOVA\nUsing the manovaR function, a descriptive overview is displayed for a comparison between groups, including univariate, multivariate and tukey post-hoc analyses.\n\nmanovaR(data[,c('Group','Autonomy','Vitality','Persistence')],\n        stand=TRUE, sign = 0.05, tukey = TRUE)\n\n[1] \"Grouping variable has only 2 levels. Tukey not applicable\"\n\n\n\nvariables Group 1Group 2F-valuep-value eta-squaredAutonomy4.27 (±1.07)2.46 (±1.34)57.48&lt;.001***0.37Vitality4.25 (±0.94)2.76 (±1.39)41.78&lt;.001***0.29Persistence3.37 (±0.92)2.31 (±1.09)28.18&lt;.001***0.22 Wilks Lambda = 0.607,F(3,95) = 20.479 , p = &lt;.001\n\n\n\n\nRegression\nUsing the summaRy function, an overview is presented with information regarding your linear (mixed) model\n\nmodel &lt;- lm(Persistence~ Condition.d * Indecisiveness.c, data=data) \nsummaRy(model)\n\n\nPredictorscoefficientsβstd. errort-valuep-value (Intercept) 1.22 0.000.323.82&lt;.001***Condition.d 1.10 0.490.25.56&lt;.001***Indecisiveness.c 1.18 0.640.522.290.02*Condition.d:Indecisiveness.c-0.83-0.720.32-2.570.01**ANOVA:SumsqMeansq(df)F statpartial η2VIFCondition.d28.4128.41131.11, p = &lt;.0010.25 1.01Indecisiveness.c 0.21 0.211 0.23, p = 0.630.0010.21Condition.d:Indecisiveness.c 6.01 6.011 6.58, p = 0.010.0710.20Residuals83.0920.91391Info: 95 observations, (9) missing obs. deletedFit: F(3,91) = 12.64, p = &lt;.001R2= 0.29, Adj. R2 = 0.27\n\n\nSignificant two-way interaction effects could be displayed using the inteRplot function.\n\ninteRplot(model,\n          pred = 'Condition.d',\n          mod = 'Indecisiveness.c',\n          outcome = 'Persistence',\n          xaxis = 'Condition',\n          moderator = 'Indecisiveness',\n          miny = 1,\n          maxy = 5,\n          xlabels=c('No choice','Choice')) \n\n[1] \"highest values not significant\"\n\n\n\n\n\n\n\nClustering\nThe clusteRsfunction of the CaviR package provides four figures showing a particular type of validation for a number of clusters. Indeed, we want to have all four of them, as we want to make a considered decision on how many clusters are in our dataset. This does not mean that all four types of validations will point towards the same number of clusters (sometimes it does, indicating strong evidence for a particular number). Therefore, you need to consider all types and explain in your reporting why you choose for a particular number of clusters.\n\n\n\n\n\n\nWhat are the validation techniques?\n\n\n\n\n\n\nElbow method: the number of clusters with both a minimum of within-cluster variation and a maximum of between-cluster variation\nthe Average Silhouette method: the number of clusters with the highest average silhouette, indicating the best quality of clustering\nthe Gap statistic method: the number of clusters with the highest Gap-statistic [@tibshirani2001]\nMajority rule: a summary of 30 indices reporting the most optimal number of clusters using the ‘NbClust’ function, including the CH index.\n\n\n\n\n\nclusteRs(df_clust)"
  },
  {
    "objectID": "posts/Correlations.html",
    "href": "posts/Correlations.html",
    "title": "Co-Relate",
    "section": "",
    "text": "Cross-sectional\nAs no packages were available providing a clean output of a correlation table, including descriptive statistics, I function was constructed in the CaviR package. By using this, a clean table will appear which can be copied wright away in Excel, Word, etc.\n\n\n\n\n\n\nNote\n\n\n\n\nFirst, make a subset of all variables you want to include in the correlation matrix. You can choose which order they have.\nRun the coRtable() function\n\n\n\n\ncorrelation_dataset &lt;- data[, c(\n  \"Extra\",\"Agree\",\"Con\",\"Neur\",\"Open\")]\n\nlibrary(CaviR)\ncoRtable(correlation_dataset)\n\n\n MSD1.2.3.4.5.1. Extra3.580.522. Agree3.660.53.22*3. Con3.430.54.06.42***4. Neur2.760.8.06-.19-.28**5. Open3.410.58.44***.22*.27**.04Note. *** p &lt;.001, ** p &lt;. 01, * p &lt; .05\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe output can be opened in Rstudio or in your browser. When copy it (CTRL + A or CMD + A), you can change the layout in your Excel or Word file to whatever you like.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to change the names of the variables, use colnames(correlation_dataset) &lt;- c(NEW_NAMES) after step 1 where you replace NEW_NAMES by a vector of names you prefer.\n\n\nMake a useful netwerk plot based on the variables in the correlation table.\n\nlibrary(qgraph)\ncorMat &lt;- cor(correlation_dataset, use = \"pairwise.complete.obs\") # Correlate data\nGraph_lasso &lt;- qgraph(corMat, graph = \"glasso\",\n                      layout = \"spring\", tuning = 0.25,\n                      labels = colnames(corMat),\n                      sampleSize = nrow(correlation_dataset))\n\n\n\n\n\n\nMultilevel correlations\nThe same CaviR package can be used for multilevel correlations (up until 2 levels).\n\n\n\n\n\n\nNote\n\n\n\n\nFirst, make a subset of all variables you want to include in the correlation matrix. You can choose which order they have, but make sure the grouping variable is the first one.\nRun the multicoR() function.\n\n\n\nThe upper diagonal will present the correlations within levels of the grouping variable. The lower diagonal will do this across groups.\n\n\n\n\n\n\nImportant\n\n\n\nThe multicoR function recognizes the first variable as the group variable, so make sure this is the first one in the dataset.\n\n\n\ncorrelation_multileveldataset &lt;- datamultilevel[, c(\n  \"ID\",\"Integration\",\"Suppression\",\"Dysregulation\")]\n\nlibrary(CaviR)\nmulticoR(correlation_multileveldataset)\n\n\n MSDICC1.2.3.1. Integration3.290.660.64-.08***.23***2. Suppression2.320.760.63-.25***.15***3. Dysregulation2.260.730.59.18***.35***Note. *** p &lt;.001, ** p &lt;. 01, * p &lt; .05\n\n\nInterpretation:\n\nThe table shows high ICC-values, indicating that 64% of the variance in the Integration variable is between groups (i.e., participants in this dataset) and 36% is located within groups, for instance.\nBetween-group correlations (below diagonal): Group’s overall mean level of Integration (i.e., across time) is related negatively with group’s overall mean on Suppression.\nWithin-group correlations (upper diagonal): When a person reports a momentary higher level of Integration compared to the overall mean across time, this person also reports a momentary lower level of Suppression compared to the overall mean across time.\n\n\n\n\n\n\n\nNote\n\n\n\nThe ICC represents the Intra-Class Correlation or the level of between-grouping variable."
  },
  {
    "objectID": "posts/Structural Modelling.html",
    "href": "posts/Structural Modelling.html",
    "title": "Check structural relationships",
    "section": "",
    "text": "What is a mediation?\n\n\n\n\n\nWith mediation analyses, we want to check to what extent an predictor-outcome association is explained by their associations with a third variable, the ‘mediator’.\nPath C refers to the association between the predictor and the outcome. This is the total effect.\n\n\n\n\nflowchart LR\n    A(Predictor) --&gt;|path C| B(Outcome)\n\n\n\n\n\nIn a mediation, we want to check whether the mediator explains this total effect. Specifically, we aim to calculate the indirect effect (i.e., effect through the mediator between predictor and outcome) and the direct effect (i.e., what remains of the total effect after controlling for the indirect effect). The indirect effect is the multiplication of path A and path B. The direct effect is path C*.\n\n\n\n\nflowchart LR\n    D(Predictor) --&gt;|path A| E(Mediator)\n    D(Predictor) --&gt;|path C*| F(Outcome)\n    E(Mediator) --&gt;|path B| F(Outcome)\n\n\n\n\n\n\n\n\nThe lavaan package allows us to extend this mediation analyses for multiple predictors, mediators and outcomes. In the current example, we want to check to what extent our condition effect (a dummy code for the conditions no choice versus choice) on the outcomes pleasure and interest, vitality, and intended persistence is explained by the mediators autonomy satisfaction and competence satisfaction.\n\n\n\n\nflowchart LR\n    A(Condition) --&gt; |B1| B(Autonomy satisfaction)\n    A(Condition) --&gt; |B2| C(Competence satisfaction)\n\n    A(Condition) --&gt; |C1| D(Pleasure and interest)\n    A(Condition) --&gt; |C2| E(Vitality)\n    A(Condition) --&gt; |C3| F(Intended persistence)\n\n    B(Autonomy satisfaction) --&gt; |A1| D(Pleasure and interest)\n    B(Autonomy satisfaction) --&gt; |A3| E(Vitality)\n    B(Autonomy satisfaction) --&gt; |A5| F(Intended persistence)\n\n    C(Competence satisfaction) --&gt; |A2| D(Pleasure and interest)\n    C(Competence satisfaction) --&gt; |A4| E(Vitality)\n    C(Competence satisfaction) --&gt; |A6| F(Intended persistence)\n\n\n\n\n\nIn describing the model, we need to provide a unique label to each pathway, so we can use this in the calculation of the indirect and total effects.\n\nlibrary(lavaan)\n\nSEM &lt;- \"\n# predictor -&gt; mediators (paths B)\nAutonomy ~ B1*Condition.d\nCompetence ~ B2*Condition.d\n\n# predictor + mediator --&gt; outcome (paths A and C*)\nPleasure ~ A1*Autonomy + A2*Competence + C1*Condition.d\nVitality ~ A3*Autonomy + A4*Competence + C2*Condition.d\nIntended_persistence ~ A5*Autonomy + A6*Competence + C3*Condition.d\n\n# calculation of an indirect effect\nB1A1 := B1*A1\nB1A2 := B1*A3\nB1A3 := B1*A5\n\nB2A2 := B2*A2\nB2A4 := B2*A4\nB2A6 := B2*A6\n\n# calculating total effect\ntotB1A1 := C1 + (B1*A1)\ntotB1A2 := C1 + (B1*A3)\ntotB1A3 := C1 + (B1*A5)\n\ntotB2A2 := C1 + (B2*A2)\ntotB2A4 := C1 + (B2*A4)\ntotB2A6 := C1 + (B2*A6)\n\"\n\nfit &lt;- sem(model = SEM, data = data)\n\nsummary(fit,\n        fit.measures = TRUE,\n        standardize = TRUE,\n        rsquare = TRUE)\n\n# useful when fit of model is not good:\nmodificationIndices(fit, sort.=TRUE, minimum.value=3)\n\n\n\n\n\n\n\nCheck the output\n\n\n\n\n\n\nsummary(fit,\n        fit.measures = TRUE,\n        standardize = TRUE,\n        rsquare = TRUE)\n\nlavaan 0.6.16 ended normally after 13 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        19\n\n                                                  Used       Total\n  Number of observations                            99         104\n\nModel Test User Model:\n                                                      \n  Test statistic                                99.060\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               504.532\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.800\n  Tucker-Lewis Index (TLI)                      -2.005\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -581.632\n  Loglikelihood unrestricted model (H1)       -532.102\n                                                      \n  Akaike (AIC)                                1201.264\n  Bayesian (BIC)                              1250.572\n  Sample-size adjusted Bayesian (SABIC)       1190.569\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.995\n  90 Percent confidence interval - lower         0.835\n  90 Percent confidence interval - upper         1.166\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.178\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                         Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Autonomy ~                                                                  \n    Conditn.d (B1)          1.193    0.160    7.432    0.000    1.193    0.598\n  Competence ~                                                                \n    Conditn.d (B2)          0.839    0.183    4.584    0.000    0.839    0.418\n  Pleasure ~                                                                  \n    Autonomy  (A1)          0.022    0.090    0.245    0.806    0.022    0.015\n    Competenc (A2)          0.897    0.079   11.409    0.000    0.897    0.615\n    Conditn.d (C1)          1.186    0.190    6.228    0.000    1.186    0.405\n  Vitality ~                                                                  \n    Autonomy  (A3)          0.110    0.095    1.154    0.248    0.110    0.082\n    Competenc (A4)          0.871    0.083   10.435    0.000    0.871    0.651\n    Conditn.d (C2)          0.673    0.202    3.329    0.001    0.673    0.251\n  Intended_persistence ~                                                      \n    Autonomy  (A5)          0.158    0.110    1.433    0.152    0.158    0.142\n    Competenc (A6)          0.438    0.096    4.539    0.000    0.438    0.396\n    Conditn.d (C3)          0.518    0.234    2.218    0.027    0.518    0.234\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .Pleasure ~~                                                           \n   .Vitality          0.185    0.057    3.248    0.001    0.185    0.345\n   .Intndd_prsstnc    0.210    0.066    3.197    0.001    0.210    0.339\n .Vitality ~~                                                           \n   .Intndd_prsstnc    0.155    0.068    2.290    0.022    0.155    0.237\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Autonomy          0.634    0.090    7.036    0.000    0.634    0.642\n   .Competence        0.825    0.117    7.036    0.000    0.825    0.825\n   .Pleasure          0.505    0.072    7.036    0.000    0.505    0.237\n   .Vitality          0.569    0.081    7.036    0.000    0.569    0.318\n   .Intndd_prsstnc    0.759    0.108    7.036    0.000    0.759    0.623\n\nR-Square:\n                   Estimate\n    Autonomy          0.358\n    Competence        0.175\n    Pleasure          0.763\n    Vitality          0.682\n    Intndd_prsstnc    0.377\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    B1A1              0.026    0.107    0.245    0.806    0.026    0.009\n    B1A2              0.131    0.115    1.141    0.254    0.131    0.049\n    B1A3              0.188    0.134    1.407    0.160    0.188    0.085\n    B2A2              0.752    0.177    4.254    0.000    0.752    0.257\n    B2A4              0.731    0.174    4.197    0.000    0.731    0.273\n    B2A6              0.367    0.114    3.226    0.001    0.367    0.166\n    totB1A1           1.212    0.158    7.691    0.000    1.212    0.414\n    totB1A2           1.317    0.203    6.498    0.000    1.317    0.454\n    totB1A3           1.374    0.211    6.507    0.000    1.374    0.490\n    totB2A2           1.939    0.243    7.991    0.000    1.939    0.663\n    totB2A4           1.917    0.252    7.613    0.000    1.917    0.678\n    totB2A6           1.553    0.214    7.274    0.000    1.553    0.571\n\nfitMeasures(fit, c(\"chisq\", \"df\", \"cfi\", \"rmsea\", \"srmr\"))\n\n chisq     df    cfi  rmsea   srmr \n99.060  1.000  0.800  0.995  0.178 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output shows that:\n\nThe model has an acceptable fit\nPathways between predictor and mediator are significant. Also, mediators are significantly related to outcomes.\nAll total effects were significant, with direct effects still being significant and 3 indirect effects being significant (through the mediator Competence). Here, we can talk about a partial mediation.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nA useful online tool to visualize structural equation model is https://app.diagrams.net/"
  },
  {
    "objectID": "posts/Structural Modelling.html#between-subject",
    "href": "posts/Structural Modelling.html#between-subject",
    "title": "Check structural relationships",
    "section": "Between-subject",
    "text": "Between-subject\n\n\n\n\nflowchart LR\n    A(Predictor X - time 1) --&gt;|autoregression| B(Predictor X time - 2)\n    A(Predictor X - time 1) --&gt;|cross-lagged| C(Predictor Y - time 2)\n    D(Predictor Y - time 1) --&gt;B(Predictor X - time 2)\n    D(Predictor Y - time 1) --&gt;C(Predictor Y - time 2)\n\n\n\n\n\n\nmodel &lt;- \n'\nVAR1_T2 + VAR2_T2 ~ VAR1_T1 + VAR2_T1\n'\n\nfit &lt;- sem(model, data = df)\nsummary(fit, \n        fit.measures = TRUE, \n        standardized = TRUE, \n        rsquare = TRUE)\nmodificationIndices(fit, sort.=TRUE, minimum.value=3)"
  },
  {
    "objectID": "posts/Structural Modelling.html#within-subject",
    "href": "posts/Structural Modelling.html#within-subject",
    "title": "Check structural relationships",
    "section": "Within-subject",
    "text": "Within-subject\nFlournoy wrote an amazingly useful package to generate a syntax for a RI-CLPM in the riclpmr package.\n\nlibrary(devtools)\n# install_github('jflournoy/riclpmr') # in case you have not installed the package yet\nlibrary(riclpmr)\nlibrary(lavaan)\n\nSelect the variables from your wide dataset.\n\ndata_riclpm &lt;- dfwide[,c(\"ID\", # also important to include the grouping variable\n                         'VARIABLEX_1','VARIABLEX_2','VARIABLEX_3','VARIABLEX_4',\n                         'VARIABLEY_1','VARIABLEY_2','VARIABLEY_3','VARIABLEY_4')]\n\n# give different column names to make the output of the model more readable\ncolnames(data_riclpm) &lt;- c(\"id\",\n                           'x1','x2','x3','x4',\n                           'y1','y2','y3','y4')\n\ndata_riclpm &lt;- data_riclpm[ , -c(1)] #remove ID\n \n# refer which columns belong to a specific variable\nvar_groups &lt;- list(\n  x=c('x1','x2','x3','x4'),\n  y=c('y1','y2','y3','y4')\n)\n\nJust run the following code. Herein, a constrained and an unconstrained model are performed and compared (via ANOVA). Based on which model provides the best fit of the data, you can check the output of the model.\n\n# construct contraint model\nmodel_text &lt;- riclpmr::riclpm_text(var_groups,\n                                   constrain_over_waves = TRUE,\n                                   constrain_ints = \"free\")\n\nfit_constraints &lt;- riclpmr::lavriclpm(riclpmModel = model_text, \n                                      data = data_riclpm,\n                                      missing = 'fiml', \n                                      meanstructure = T, \n                                      int.ov.free = T)\n# construct unconstraint model\nmodel_text &lt;- riclpmr::riclpm_text(var_groups,\n                                   constrain_over_waves = FALSE,\n                                   constrain_ints = \"free\")\n\nfit_noconstraints &lt;- riclpmr::lavriclpm(riclpmModel = model_text, \n                                        data = data_riclpm,\n                                        missing = 'fiml', \n                                        meanstructure = T, \n                                        int.ov.free = T)\n\n# run this to compare constraint and unconstraint model in terms of data fit\nanova(fit_constraints,fit_noconstraints)\n\n# Check the output of the chosenmodel\nsummary(fit_constraints,\n        fit.measures = TRUE,\n        standardize = TRUE,\n        rsquare = TRUE)"
  },
  {
    "objectID": "posts/Clustering.html",
    "href": "posts/Clustering.html",
    "title": "ClusteRing",
    "section": "",
    "text": "First, we standardize all cluster variables make a subset of our dataframe, only and only including the cluster variables. This dataset will be used to perform some validation techniques in order to select the most accurate number of clusters. In this example, we use five cluster variables: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\n\n# describe the cluster variables\nclustervariables &lt;- c(\"Open\",\"Con\",\"Extra\",\"Agree\",\"Neur\")\n\n# make a dataset only with those \n# having assessments for all cluster variables\ndata_complete &lt;- data[complete.cases(data[,clustervariables]),]\n\n# make a subset with only the cluster variables \n# to check for clusters\ndf_clust &lt;- data_complete[,clustervariables]\n\n# standardize all variables\ndf_clust &lt;- scale(df_clust,scale=TRUE)\n\n# save it as a data frame to make sure \n# all other functions work properly\ndf_clust &lt;- as.data.frame(df_clust)"
  },
  {
    "objectID": "posts/Clustering.html#preparatory-steps",
    "href": "posts/Clustering.html#preparatory-steps",
    "title": "ClusteRing",
    "section": "",
    "text": "First, we standardize all cluster variables make a subset of our dataframe, only and only including the cluster variables. This dataset will be used to perform some validation techniques in order to select the most accurate number of clusters. In this example, we use five cluster variables: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\n\n# describe the cluster variables\nclustervariables &lt;- c(\"Open\",\"Con\",\"Extra\",\"Agree\",\"Neur\")\n\n# make a dataset only with those \n# having assessments for all cluster variables\ndata_complete &lt;- data[complete.cases(data[,clustervariables]),]\n\n# make a subset with only the cluster variables \n# to check for clusters\ndf_clust &lt;- data_complete[,clustervariables]\n\n# standardize all variables\ndf_clust &lt;- scale(df_clust,scale=TRUE)\n\n# save it as a data frame to make sure \n# all other functions work properly\ndf_clust &lt;- as.data.frame(df_clust)"
  },
  {
    "objectID": "posts/Clustering.html#validation-before-clustering",
    "href": "posts/Clustering.html#validation-before-clustering",
    "title": "ClusteRing",
    "section": "Validation before clustering",
    "text": "Validation before clustering\nBefore we actually want to cluster, we already can have an indication to what extent ‘our data is clusterable’. This is done using the Hopkin statistic (HOPKINS and SKELLAM 1954), which can be interpreted as a ‘chance of finding meaningful clusters’. When this is 0.50, this means there is an equally high chance of observing meaningful clusters as finding meaningless clusters. The higher, the better.\nIn our experience, we noticed that, when having a Hopkin statistic of, for instance, 0.52 or 0.56, the validation techniques of finding the optimal number of clusters indeed were inconclusive.\n\nlibrary(factoextra)\n\n# original dataset\nres.o &lt;- get_clust_tendency(df_clust,\n                            n = nrow(df_clust)-1,\n                            graph=FALSE)\nH_dataset &lt;- round(res.o$hopkins_stat,3)\n\n# random dataset\nrandom_dffull &lt;- as.data.frame(apply(df_clust,2,\n                                     function(x){runif(length(x),\n                                                       min(x),\n                                                       max(x))}))\n\n# testing tendency\nres.r &lt;- get_clust_tendency(random_dffull, \n                            n = nrow(random_dffull)-1,\n                            graph=FALSE)\n\nH_random &lt;- round(res.r$hopkins_stat,3)\n\n# make table for output\ntable_H &lt;- cbind(H_dataset,H_random)\ncolnames(table_H) &lt;- c('df_clust','random dataset')\nrownames(table_H) &lt;- 'Hopkin statistic'\ntable_H\n\n                 df_clust random dataset\nHopkin statistic    0.585          0.482\n\n\nHere, the H-statistics shows a value of .59, which is higher than .50, meaning there is a chance of having meaningful clusters.(Kaufman and Rousseeuw 1990)"
  },
  {
    "objectID": "posts/Clustering.html#validation-during-clustering",
    "href": "posts/Clustering.html#validation-during-clustering",
    "title": "ClusteRing",
    "section": "Validation during clustering",
    "text": "Validation during clustering\nThe clusteRsfunction of the CaviR package provides four figures showing a particular type of validation for a number of clusters. Indeed, we want to have all four of them, as we want to make a considered decision on how many clusters are in our dataset. This does not mean that all four types of validations will point towards the same number of clusters (sometimes it does, indicating strong evidence for a particular number). Therefore, you need to consider all types and explain in your reporting why you choose for a particular number of clusters.\n\n\n\n\n\n\nWhat are the validation techniques?\n\n\n\n\n\n\nElbow method: the number of clusters with both a minimum of within-cluster variation and a maximum of between-cluster variation\nthe Average Silhouette method: the number of clusters with the highest average silhouette, indicating the best quality of clustering (Kaufman and Rousseeuw 1990)\nthe Gap statistic method: the number of clusters with the highest Gap-statistic (Tibshirani, Walther, and Hastie 2001)\nMajority rule: a summary of 30 indices reporting the most optimal number of clusters using the ‘NbClust’ function (Charrad et al. 2014), including the CH index (Calinski and Harabasz 1974)\n\n\n\n\n\nlibrary(CaviR)\nclusteRs(df_clust)"
  },
  {
    "objectID": "posts/Clustering.html#after-having-decided-the-number-of-clusters",
    "href": "posts/Clustering.html#after-having-decided-the-number-of-clusters",
    "title": "ClusteRing",
    "section": "After having decided the number of clusters",
    "text": "After having decided the number of clusters\nAfter all validation techniques, you can choose the number of clusters and perform the hkmeans function.\n\n# function for two-step clustering procedure\nhkm &lt;- hkmeans(data_complete[,clustervariables], \n               k = 4, # chosen number of clusters\n               hc.metric=\"euclidian\",\n               hc.method='ward.D2',\n               iter.max = 10,\n               km.algorithm = \"Hartigan-Wong\")\n\n# assign cluster variable to your dataset\ndata_complete$clusters &lt;- as.factor(hkm$cluster)\n\n# check proportions of participants into the clusters\nlibrary(questionr)\nfreq(data_complete$clusters)\n\n   n    % val%\n1 24 23.8 23.8\n2 30 29.7 29.7\n3 21 20.8 20.8\n4 26 25.7 25.7\n\n\nUsing the following code, we can have a barplot. Here, we work with the standardized cluster variables, although it might be interesting to have a figure with the raw values as the standardized variables make relative differences. Then, we need to make sure that we also interpret the absolute values (lower values do not mean low values!):\n\nlibrary(ggplot2); library(rstatix)\n\n# calculate means of standardized variables by cluster levels\nhkmdata &lt;- as.data.frame(\n              aggregate(data_complete[,c(clustervariables)],\n                        by=list(cluster=data_complete$clusters),\n                        mean))\n\nhkmdata[,2:(length(clustervariables)+1)] &lt;- as.data.frame(scale(\n  hkmdata[,2:(length(clustervariables)+1)], \n  scale=TRUE))\n\n# restructure into long format\ndata_long &lt;- gather(hkmdata, type, measurement,\n                    names(df_clust), \n                    factor_key=TRUE)\n# change column names\ncolnames(data_long) &lt;- c('Clusters','Type','Value')\n\n# make sure they have the right format\ndata_long$Clusters &lt;- as.numeric(data_long$Clusters)\ndata_long$Type &lt;- as.factor(data_long$Type)\n\n# if you want to change the order of the clusters, \n# this can be done here:\ndata_long$Clusters &lt;- as.character(data_long$Clusters)\ndata_long$Clusters &lt;- as.factor(data_long$Clusters)\nlevels(data_long$Clusters) &lt;- c(\"3\",\"4\",\"1\",\"2\") # preferred order\ndata_long$Clusters &lt;- as.character(data_long$Clusters)\ndata_long$Clusters &lt;- as.numeric(data_long$Clusters)\n\n# figure\nggplot(data=data_long, \n       aes(x=Clusters, y=Value, fill=Type, linetype=Type)) +\n  geom_bar(stat=\"identity\",width = 0.7,\n           position=position_dodge(),\n           color='black')+\n  \n  # y axis\n  scale_y_continuous(limits = c(-1.4,1.4))+\n\n  # provide color to bars\n  scale_fill_manual(\"OCEAN\", # name of cluster variables \n                    \n                     # labels for cluster variables\n                    labels=clustervariables,\n                    \n                    # colors for cluster variables\n                    values=c('#2e2e2e','#858585',\n                             '#cecece','#ffffff',\n                             \"#2F3D4E\") )+\n  \n  # provide different linetype to bars \n  # (useful for black/white printing)\n  scale_linetype_manual(\"OCEAN\", # name of cluster variables \n                        \n                        # labels for cluster variables\n                        labels=clustervariables,\n                        \n                        # linetypes for cluster variables\n                        values=c('dotted','dotdash',\n                                 'dashed','solid','longdash'))+\n  \n  # settings for x-axis\n   scale_x_continuous(name=\"Cluster\",  # name for x axis\n                      breaks=c(1:4), # 'breaks' = number of clusters\n                      \n                      # labels for clusters. \n                      # Here you can add the proportions\n                      # underneath the name, using \\n\n                      labels= c( \"Cluster 1\\n24%\", \n                                 \"Cluster 2\\n30%\",\n                                 \"Cluster 3\\n21%\",\n                                 \"Cluster 4\\n25%\"))+\n  \n  # settings for layout\n  theme(\n    legend.position = 'right',\n    legend.spacing.x = unit(1, 'mm'),\n    axis.title.x = element_blank(),\n    plot.caption = element_text(color = \"black\")\n  )+\n  \n  # ggplot theme\n  theme_bw()\n\n\n\n\nBased on the output of the figure - which can help in interpreting the content of a cluster - now you can provide labels to the clusters in the dataset itself. This variable can be used in between-cluster analyses (can be done using frequency tables or (M)ANOVA)\n\nlevels(data_complete$clusters) &lt;- c('NAME_clus1','NAME_clus2',\n                                    'NAME_clus3','NAME_clus4')"
  },
  {
    "objectID": "posts/Clustering.html#validation-after-clustering",
    "href": "posts/Clustering.html#validation-after-clustering",
    "title": "ClusteRing",
    "section": "Validation after clustering",
    "text": "Validation after clustering\nEven after we chose the number of clusters and even labelled them, we can perform a validation technique to check the ‘stability’ of the clusters. Basically, it performed the clustering analyses on one part of the dataset, and uses the K-mean values as the input of a clustering analysis on the other part of the dataset:\n\n# divide dataset into two parts: subset A and B\nset.seed(7)\nss &lt;- sample(1:2,size=nrow(data_complete),\n             replace=TRUE,prob=c(0.5,0.5))\nsubsetA &lt;- data_complete[ss==1,c('clusters',clustervariables)]\nsubsetB &lt;- data_complete[ss==2,c('clusters',clustervariables)]\n\n# perform clustering analysis in both parts\nhkmA &lt;- hkmeans(subsetA[,clustervariables], \n                k = 4,\n                hc.metric=\"euclidian\",\n                hc.method='ward.D2',\n                iter.max = 10,\n                km.algorithm = \"Hartigan-Wong\")\n\nhkmB &lt;- hkmeans(subsetB[,clustervariables], \n                k = 4,\n                hc.metric=\"euclidian\",\n                hc.method='ward.D2',\n                iter.max = 10,\n                km.algorithm = \"Hartigan-Wong\")\n\n# use the output of the cluster analysis in \n# each subset as the initial starting points \n# for a clustering analysis in the other subset\nkmeanAB &lt;- kmeans(subsetA[,clustervariables], \n                  # here we refer to the values of the cluster analyses \n                  # in the other subset\n                  hkmB$centers,  \n                  iter.max=10, \n                  nstart=1,\n                  algorithm = \"Hartigan-Wong\")\nsubsetA$AB &lt;- as.factor(kmeanAB$cluster) # assign it to the subset\n\nkmeanBA &lt;- kmeans(subsetB[,clustervariables], \n                  hkmA$centers, \n                  iter.max=10, \n                  nstart=1,\n                  algorithm = \"Hartigan-Wong\")\nsubsetB$BA &lt;- as.factor(kmeanBA$cluster)\n\nSo, when this is done, we want to have an indication of how good the clustering in a different part of the dataset results in a good clustering in another part of the dataset. The stability is checked with a Cohen’s Kappa-index k testing the correspondence between the subsample-clustering results and the clustering results forming from the original clustering procedure. An acceptable cluster stability is assumed when k is .60 or higher (Asendorpf et al., 2001). The final results of the clustering procedure will be presented in a barplot with the standardized cluster variables as a function of the cluster classification.\nBeware, we might need to restructure the table to make sure we have the same clusters being compared.\n\n# check in subset A\nmytableAB &lt;- with(subsetA, table(clusters,AB))\nmytableAB # table. When ok, do nothing. \n\n        AB\nclusters  1  2  3  4\n       1  9  0  0  3\n       2  0  7  0 11\n       3  0  3  7  0\n       4  1  2  4  0\n\n# When not oke, change order of columns:\ncolnames(mytableAB) &lt;- c(\"1\",\"4\",\"3\",\"2\")\nmytableAB &lt;- mytableAB[ , c(\"1\",\"2\",\"3\",\"4\")]\n\n# computer Kappa\nlibrary(vcd)\nKappa(mytableAB)\n\n            value     ASE     z  Pr(&gt;|z|)\nUnweighted 0.4851 0.09241 5.249 1.529e-07\nWeighted   0.5151 0.09311 5.532 3.162e-08\n\n# repeat for subset B:\nmytableBA &lt;- with(subsetB, table(clusters,BA))\nmytableBA# table. When ok, do nothing. \n\n        BA\nclusters  1  2  3  4\n       1  0 12  0  0\n       2  0  0  0 12\n       3  6  0  3  2\n       4 13  6  0  0\n\n# When not oke, change order of columns:\ncolnames(mytableBA) &lt;- c(\"4\",\"1\",\"3\",\"2\")\nmytableBA &lt;- mytableBA[ , c(\"1\",\"2\",\"3\",\"4\")]\n\nKappa(mytableBA)\n\n            value     ASE     z  Pr(&gt;|z|)\nUnweighted 0.6464 0.07888 8.194 2.519e-16\nWeighted   0.6495 0.09053 7.175 7.237e-13"
  },
  {
    "objectID": "posts/RegRession.html",
    "href": "posts/RegRession.html",
    "title": "Regression modelling",
    "section": "",
    "text": "Cross-sectional\nTime to build our model. Here we have two main effects and one interaction effect of the predictor Condition (i.e., received no choice, received choice) and Indecisiveness (i.e., level of one’s indecisiveness). Condition is a (numeric) dummy code, Indecisiveness is centered. The outcome Pleasure is not centered.\n\n\n\n\n\n\nWhat about categorical predictors: dummy or effect coding?\n\n\n\n\n\nBefore building our model, we need to make sure that all our input is ok. For instance, we want to have dummy or effect codings instead of factor variables. Here, we work with the example of a factor with 3 levels, resulting in 2 dummy codings:\n\ndf$dummy1 &lt;- as.factor(df$VAR1)\nlevels(df$dummy1) &lt;- c(0,1,0)\ndf$dummy1 &lt;- as.numeric(df$dummy1)\n\ndf$dummy2 &lt;- as.factor(df$VAR1)\nlevels(df$dummy2) &lt;- c(0,0,1)\ndf$dummy2 &lt;- as.numeric(df$dummy2)\n\nor you want to use effect codings.\nTo my opinion, this is the most useful one to do as things are centered in our interpretation. When using dummy, you need to interpret the main effect of a particular variable ‘when all other coefficients are kept stable’. In the case of a dummy coding, this means that this refers to the main effect in presence of the reference value of the dummy coding. When doing effect coding, this is not the case and you have a more clear interpretation of the main effect.\n\ndf$dummy1 &lt;- ifelse(df$VAR1 == \"group2\", 1, 0)\ndf$dummy2 &lt;- ifelse(df$VAR1 == \"group3\", 1, 0)\ndf$dummy3 &lt;- ifelse(df$VAR1 == \"group4\", 1, 0)\n\n\n\n\n\n\n\n\n\n\nWhat about numeric predictors: center or standardize?\n\n\n\n\n\nIt is to center numeric variables. When centering, you keep the standard deviation. When standardizing, this is forced to 1. This is a choice, but I, personally, like it when the initial variance is kept in terms of interpreting the results.\n\ndf$VAR1.c &lt;- as.numeric(scale(df$VAR1,scale=FALSE,center=TRUE))\n\n\n\n\n\nmodel &lt;- lm(Persistence~ Condition.d * Indecisiveness.c, data=data) \n\n\n\n\n\n\n\nImportant\n\n\n\nIn this model, we immediatly mentioned the interaction effect because the lm function in R calculates both the main effects and interaction effects by default. This saves time, but beware an interaction effect is not interpretable without main effects in a model.\n\n\nCheck the output of the model using the summaRy function in the CaviR package.\n\nlibrary(CaviR)\nsummaRy(model)\n\n\nPredictorscoefficientsβstd. errort-valuep-value (Intercept) 1.22 0.000.323.82&lt;.001***Condition.d 1.10 0.490.25.56&lt;.001***Indecisiveness.c 1.18 0.640.522.290.02*Condition.d:Indecisiveness.c-0.83-0.720.32-2.570.01**ANOVA:SumsqMeansq(df)F statpartial η2VIFCondition.d28.4128.41131.11, p = &lt;.0010.25 1.01Indecisiveness.c 0.21 0.211 0.23, p = 0.630.0010.21Condition.d:Indecisiveness.c 6.01 6.011 6.58, p = 0.010.0710.20Residuals83.0920.91391Info: 95 observations, (9) missing obs. deletedFit: F(3,91) = 12.64, p = &lt;.001R2= 0.29, Adj. R2 = 0.27\n\n\n\n\n\n\n\n\nHow to interpret this output?\n\n\n\nThe output provides several sources of information:\n\nRaw and standardized coefficients\nStandard errors and t-values, with p-values\nthe ANOVA output of the model, providing partial eta-squares and Variance Inflation Factors (to check for multicollinearity)\nNumber of used observations and how many were excluded from the analyses\nTotal fit for the model and R-squared values\n\n\n\nWhen selecting the whole output (CTRL + A or CMD + A), one could paste this into Excel or Word.\n\n\n\n\n\n\nHow to interpret the partial eta-squared?\n\n\n\n\n\n\nsmall when ηp2 &gt; .0099\nmedium when ηp2 &gt; .0588\nlarge when ηp2 &gt;.1379\n(Cohen 2013)\n\n\n\n\n\n\n\n\n\n\nWhat about model assumptions?\n\n\n\n\n\nImportant is to check to what your model does satisfy all models. A nice way to do this is using the check_model function, however this might take a while (especially in more complex models). You can check all diagnostics separately (which may be faster):\nModel assumptions:\n\nLinearity: is my model linear?\n\nCheck?: (1) is the point cloud at random and (2) is the blue line in plot 2 similar to the horizontal line in plot 2?\nViolation?: consider another relationship (e.g. cubric, curvilinear)\n\nNormality: is the distribution of my parameters / residuals normal?\n\nCheck?: do I have a Q-Q plot in plot 3 where all datapoints are as close too the diagonal? Is the distribution as similar as possible to the normal distribution in plot 8?\nViolation?: consider transformations of your parameters or check which variable is necessary to add to the model\n\nHomoscedasticity: is the spread of my data across levels of my predictor the same?\n\nCheck?: (1) is the point cloud at random and (2) is the blue line in plot 2 similar to the horizontal line in plot 2? (3) Is there a pattern in plot 4?\nViolation?: in case of heteroscedasticity, you will have inconsistency in calculation of standard errors and parameter estimation in the model. This results in biased confidence intervals and significance tests.\n\nIndependence: are the errors in my model related to each other?\nInfluential outliers: are there outliers influential to my model?\n\nCheck?: is the blue line in plot 7 curved?\nViolation?: this could be problematic for estimating parameters (e.g. mean) and sum of squared and biased results.\n\n\n\nlibrary(performance)\ncheck_normality(model)\n\nWarning: Non-normality of residuals detected (p = 0.031).\n\ncheck_outliers(model)\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n\ncheck_heteroscedasticity(model)\n\nOK: Error variance appears to be homoscedastic (p = 0.054).\n\nmulticollinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n        Term  VIF       VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Condition.d 1.01 [1.00, 8.59e+09]         1.00      0.99     [0.00, 1.00]\n\nHigh Correlation\n\n                         Term   VIF       VIF 95% CI Increased SE Tolerance\n             Indecisiveness.c 10.21 [7.20,    14.69]         3.20      0.10\n Condition.d:Indecisiveness.c 10.20 [7.20,    14.67]         3.19      0.10\n Tolerance 95% CI\n     [0.07, 0.14]\n     [0.07, 0.14]\n\n\nSo, here, the model diagnostics tell us the residuals are slightly non-normal, no outliers are detected, the heteroscedascticity assumption is satisfied and we have no multicollinearity. More information about this can be found in the package performance\n\n\n\nThe inteRplot function in the CaviR package provides an informative overview when checking a two-way interaction effect. Rather than only representing the interaction effect by the two values equaling +- 1 standard deviation from the mean of the moderator, it is important to have a full overview to have an accurate and full interpretation.\n\n\n\n\n\n\nNote\n\n\n\nFollowing information is required to use the function:\n\nname of the model\nname of the predictor and the moderator\nlabels for the outcome, x axis, moderator\nrange of y-values\nlabels for the x axis\n\n\n\n\nlibrary(CaviR)\ninteRplot(model,\n          pred = 'Condition.d',\n          mod = 'Indecisiveness.c',\n          outcome = 'Persistence',\n          xaxis = 'Condition',\n          moderator = 'Indecisiveness',\n          miny = 1,\n          maxy = 5,\n          xlabels=c('No choice','Choice'))\n\n[1] \"highest values not significant\"\n\n\n\n\n\n\n\n\n\n\n\nHow to interpret this output?\n\n\n\nThe output of this two-way interaction figure provides several sources of information.\nIn the figure itself:\n\nthe (classic) ‘+- standard deviation’ lines\na blue line representing the slope of the lowest value of the moderator\na red line representing the slope of the highest value of the moderator\na grey area going from the minimum to the maximum value of the moderator\na dark grey area representing all slopes for which the interaction effect is not significant (based on the Johnson-Neyman interval)\n\nOn the right, we have numerical information in the legend, showing the minimum and maximum value of the moderator, the numerical value of the Johnson-Neyman interval and the standardized simple slope coefficients (with statistic) for the slopes of the +- 1 standard deviations.\n\n\nAs can be noticed in the figure, it is important to have a full overview of the interaction effect, doing this by including the Johnson-Neyman interval. Based on solely the standard deviation values, we would have thought that “the lower one’s indecisiveness, the more persistence is reported when choice was provided”. However, we see that this effect is not significant for those having (standardized) values on indecisiveness higher than 0.64. From then on, the effect of having choice or not is non-significant on one’s intended persistence.\n\n\nMultilevel Modeling\nBoth the summaRy and inteRplot functions are also applicable for multilevel modeling, when using the lmer function of the lme4 package. An example:\n\nlibrary(lme4); library(lmerTest); library(CaviR)\n\nmodel &lt;- lmer(Depression ~ Dysregulation.c*Integration.c + (1|ID), data=datamultilevel)\nsummaRy(model)\n\n\nPredictorscoefficientsβstd. errort-valuep-value (Intercept) 1.69 0.000.01293.68&lt;.001***Dysregulation.c 0.55 0.640.0169.99&lt;.001***Integration.c-0.10-0.100.01-10.92&lt;.001***Dysregulation.c:Integration.c-0.06-0.050.01-5.72&lt;.001***Random effects:groupStd. Dev.ID0.37Residual0.30ANOVA:SumsqMeansq(NumDF, DenDF)F statpartial η2VIFDysregulation.c459.54459.54(1.00, 7350.68)4898.52, p = &lt;.0010.401.04Integration.c 11.18 11.18(1.00, 7350.99) 119.17, p = &lt;.0010.021.15Dysregulation.c:Integration.c  3.07  3.07(1.00, 7271.74)  32.71, p = &lt;.0010.001.11Residuals292.7210.047355Info: 7355 observations, (0) missing obs. deletedAIC = 9984.01, BIC = 10025.43R2 conditional = 0.76, R2 marginal = 0.4ICC = 0.59\n\n\n\nlibrary(CaviR)\ninteRplot(model,\n          pred = 'Dysregulation.c',\n          mod = 'Integration.c',\n          outcome = 'Depression',\n          xaxis = 'Dysregulation',\n          moderator = 'Integration',\n          miny = 1,\n          maxy = 4,\n          xlabels=c('Low','High'))\n\n[1] \"no interval detected within range\"\n\n\n\n\n\nIn this interaction effect, there are no non-significant (dark grey) slopes because the interaction effect is significant for each of the moderator’s values.\n\n\n\n\n\nReferences\n\nCohen, Jacob. 2013. Statistical Power Analysis for the Behavioral Sciences. Academic Press."
  },
  {
    "objectID": "posts/Data_Set.html",
    "href": "posts/Data_Set.html",
    "title": "Get your dataset ready",
    "section": "",
    "text": "To work with R, you need packages, including useful functions. These will save time because they provide an easy way to run complex analyses. By installing these packages on your computer, you can make use of these functions. Indeed, they are already written for you, so you don’t have to code yourself.\n\n\n\n\n\n\nTip\n\n\n\nAt each start of a new R session (e.g., after shutting down your computer), you have to load the packages you want to use. Instead of using library(X) for each package, you can make a list so they can be loaded all at once.\n\n\nFollowing packages are required for (1), (2) and (3):\n\n# my list of packages (as an example)\nx&lt;-c('readxl','haven','psych','sjPlot','writexl','foreign')\n\n# do this only once\ninstall.packages(x) \n\n# do this at the start of each session\nlapply(x, require, character.only = TRUE) \n\n# use this for only one package\nlibrary(PACKAGE_NAME)\n\nAlso important is that R knowns in which folder you want to work. By following code, you set your work directory in which R can find the required datasets and also can save the files you want to save.\n\nsetwd(\"/Users/joachimwaterschoot/Downloads/Analyses\")\n\n\n\n\nDatasets can be loaded in every format. Beware, these functions also include more options (e.g., a specific tab in an excel file). More information can be found on the page of the packages (search for the function in Google)\n\ndf &lt;- readRDS('FILE.rds')\ndf &lt;- read_xlsx('FILE.xlsx')\ndf &lt;- read.spss(\"FILE.sav\",\n                use.value.labels = FALSE,\n                to.data.frame=TRUE)\n\nAfter data is loaded, you can check whether it occurred correctly. Do this by checking the column names and the dimension (number of rows X number of columns).\n\nnames(df) #column names\ndim(df) #how many rows and columns\nhead(df,10) #check the first 10 rows"
  },
  {
    "objectID": "posts/Data_Set.html#get-ready",
    "href": "posts/Data_Set.html#get-ready",
    "title": "Get your dataset ready",
    "section": "",
    "text": "To work with R, you need packages, including useful functions. These will save time because they provide an easy way to run complex analyses. By installing these packages on your computer, you can make use of these functions. Indeed, they are already written for you, so you don’t have to code yourself.\n\n\n\n\n\n\nTip\n\n\n\nAt each start of a new R session (e.g., after shutting down your computer), you have to load the packages you want to use. Instead of using library(X) for each package, you can make a list so they can be loaded all at once.\n\n\nFollowing packages are required for (1), (2) and (3):\n\n# my list of packages (as an example)\nx&lt;-c('readxl','haven','psych','sjPlot','writexl','foreign')\n\n# do this only once\ninstall.packages(x) \n\n# do this at the start of each session\nlapply(x, require, character.only = TRUE) \n\n# use this for only one package\nlibrary(PACKAGE_NAME)\n\nAlso important is that R knowns in which folder you want to work. By following code, you set your work directory in which R can find the required datasets and also can save the files you want to save.\n\nsetwd(\"/Users/joachimwaterschoot/Downloads/Analyses\")"
  },
  {
    "objectID": "posts/Data_Set.html#welcome-data",
    "href": "posts/Data_Set.html#welcome-data",
    "title": "Get your dataset ready",
    "section": "",
    "text": "Datasets can be loaded in every format. Beware, these functions also include more options (e.g., a specific tab in an excel file). More information can be found on the page of the packages (search for the function in Google)\n\ndf &lt;- readRDS('FILE.rds')\ndf &lt;- read_xlsx('FILE.xlsx')\ndf &lt;- read.spss(\"FILE.sav\",\n                use.value.labels = FALSE,\n                to.data.frame=TRUE)\n\nAfter data is loaded, you can check whether it occurred correctly. Do this by checking the column names and the dimension (number of rows X number of columns).\n\nnames(df) #column names\ndim(df) #how many rows and columns\nhead(df,10) #check the first 10 rows"
  },
  {
    "objectID": "posts/Data_Set.html#put-your-variables-in-the-right-format",
    "href": "posts/Data_Set.html#put-your-variables-in-the-right-format",
    "title": "Get your dataset ready",
    "section": "Put your variables in the right format",
    "text": "Put your variables in the right format\nImportantly, you want to have variables in the right format. This is important before starting analyses.\n\n# formatting into numeric variable\ndf$VARIABLE1 &lt;- as.numeric(df$VARIABLE1)\n\n# formatting into a categorical variable\ndf$VARIABLE2 &lt;- as.factor(df$VARIABLE2)\n# check the levels\nlevels(df$VARIABLE2)\n# provide different labels to the levels if necessary\nlevels(df$VARIABLE2) &lt;- c('LEVEL1','LEVEL2')\n\n\n\n\n\n\n\nHow to reverse a variable?\n\n\n\n\n\nTo reverse a numeric value or to change specific values to another value in a column, you can use the recode function…\n\nlibrary(dplyr)\ndf$item_r &lt;- as.factor(recode(df$item, '1'='5', '2'='4','3'='3','4'='2','5'='1'))\n\n… or you can subtract that column from its highest value + 1.\nHere, a 1-5 scale is reversed by subtracting it from 6. By doing this, 5 becomes 1, 4 becomes 2, etc.\n\ndf$item_r &lt;- 6-as.numeric(df$item)\n\n\n\n\n\n\n\n\n\n\nHow to match a variable to another dataset?\n\n\n\n\n\nWhen you want to add information to a dataset (e.g., df), based on another dataset (e.g., df_other), you can use the match() function to first match values of the same variable in the same datasets (e.g., participation number).\n\ndf$VARIABLE1 &lt;- df_other$VARIABLE2[match(df$ID,df_other$df)]\n\n\n\n\n\n\n\n\n\n\nHow to rename a column?\n\n\n\n\n\n\nnames(df)[names(df) == 'old.var.name'] &lt;- 'new.var.name'"
  },
  {
    "objectID": "posts/Data_Set.html#create-variables",
    "href": "posts/Data_Set.html#create-variables",
    "title": "Get your dataset ready",
    "section": "Create variables",
    "text": "Create variables\nIn the keys.list, you make an overview of which items belong to which variable. Do this for only those containing at least 2 items or more.\n\n\n\n\n\n\nImportant\n\n\n\nOf course, this can only be done with numeric variables.\n\n\n\nkeys.list &lt;- list(\n  VARIABLE1 = c(\"ITEM1\",\"ITEM2\"),\n  VARIABLE2 = c(\"ITEM1\",\"ITEM2\")\n)\n\nThis list will be used in the following code to calculate your variables and to add them in the described order to the dataset.\n\n\n\n\n\n\nHow to rename a column?\n\n\n\n\n\nIn this code, the name of the dataframe is df. Make sure you replace this label when you have another name\n\n\n\n\nlibrary(psych)\n\ncolumns &lt;- unlist(keys.list, use.names=FALSE) \nscaleitems &lt;- df[,columns] \nscaleitems &lt;- sapply(scaleitems, as.numeric) \ndf &lt;- df[, ! names(df) %in% columns, drop = F]\n\nkeys &lt;- make.keys(scaleitems,keys.list)\nscores &lt;- scoreFast(keys, scaleitems, impute=\"none\")\n\nmeans &lt;- as.data.frame(scores)\ncolnames(means) &lt;- sub(\"-A.*\", \"\", colnames(means))\n\ndf &lt;- cbind(df, scaleitems,means)\n\nThe sjt.itemanalysis function of the sjPlot package provides a nice overview of the internal consistencies of your variables.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\noverview of items\npercentage of missing values\nstandard deviation\nskewness: the higher, the skewer\nitem difficulty: should range between .20 and .80. Ideal value is p+(1-p)/2 (mostly between .50 and .80)\nitem discrimination: acceptable cut-off of .20. The closer to 1, the better.\nCronbach’s Alpha if item was removed from scale\nmean (or average) inter-item correlation: acceptable between .20 and .40\nCronbach’s Alpha: acceptable cut-off of .70\n\n\n\n\n\nsjt.itemanalysis(df[,c(keys.list$VARIABLE1)])\nsjt.itemanalysis(df[,c(keys.list$VARIABLE2)])"
  },
  {
    "objectID": "posts/Data_Set.html#wide-to-long",
    "href": "posts/Data_Set.html#wide-to-long",
    "title": "Get your dataset ready",
    "section": "Wide to long",
    "text": "Wide to long\nFirst, we make a list of those variables we want to restructure.\n\nlonglist &lt;- list(\n  VAR1=c('VAR1_1','VAR1_2','VAR1_3','VAR1_4'),\n  VAR2=c('VAR2_1','VAR2_2','VAR2_3','VAR2_4')\n)\n\nThe list is used in the code below:\n\ndflong &lt;- reshape(data = df, # name of the dataset\n                  idvar = \"ID\", # group variable including dependent variance\n                  varying = longlist,\n                  direction=\"long\",\n                  v.names = names(longlist),\n                  sep=\"_\")"
  },
  {
    "objectID": "posts/Data_Set.html#long-to-wide",
    "href": "posts/Data_Set.html#long-to-wide",
    "title": "Get your dataset ready",
    "section": "Long to wide",
    "text": "Long to wide\nComplete the following function:\n\ndfwide &lt;- reshape(dflong, # name of the dataset\n                  idvar = \"ID\",  # name of the grouping variable including dependent variance\n                  timevar = \"time\", # time variable\n                  direction = \"wide\")\n\nhead(dfwide) # check whether the function did what you expected"
  },
  {
    "objectID": "posts/Categorical variables.html",
    "href": "posts/Categorical variables.html",
    "title": "Work with categorical variables",
    "section": "",
    "text": "Frequencies\nWhen you want to check whether, for instance, more male are present in a specific group, you can get a clean contingency table with a chi-square test by following code. Of course, you can work with all the different options as you wish:\n\nlibrary(sjPlot)\n\ntab_xtab(df$VAR1,df$VAR2,\n         show.cell.prc = FALSE,\n         show.row.prc = TRUE,\n         show.col.prc = FALSE,\n         show.legend = TRUE,\n         show.na = FALSE,\n         show.summary=TRUE)\n\n\n\n\n\n \n Group\n Gender\n Total\n \n \n\n Male\n Female\n \n \n \nGroup 1\n2850 %\n2850 %\n56100 % \n\n \n \nGroup 2\n2245.8 %\n2654.2 %\n48100 % \n\n \n \nTotal\n5048.1 %\n5451.9 %\n104100 % \n\nχ2=0.052 · df=1 · φ=0.042 · p=0.820 \n\n \n \n observed values\n % within Group\n \n\n\n\n\n\n(M)ANOVA\nThe manovaR function of the CaviR package allows to have a full and informative overview of the role of a categorical variable in prediction of several numeric variables.\n\n\n\n\n\n\nThe function provides:\n\n\n\n\n\nThe function provides:\n\ndescriptive statistics for each level of the categorical variable\nunivariate analyses with a p-value for statistical significance and a partial eta-squared for practical significance\nmultivariate analysis with the Wilks’ Lambda\n\n\n\n\n\n\n\n\n\n\nHow to interpret the partial eta-squared?\n\n\n\n\n\n\nsmall when ηp2 &gt; .0099\nmedium when ηp2 &gt; .0588\nlarge when ηp2 &gt;.1379\n(Cohen 2013)\n\n\n\n\n\nlibrary(CaviR)\nmanovaR(data[,c('Group','Autonomy','Vitality','Persistence')],\n        stand=TRUE, sign = 0.05, tukey = TRUE)\n\n[1] \"Grouping variable has only 2 levels. Tukey not applicable\"\n\n\n\nvariables Group 1Group 2F-valuep-value eta-squaredAutonomy4.27 (±1.07)2.46 (±1.34)57.48&lt;.001***0.37Vitality4.25 (±0.94)2.76 (±1.39)41.78&lt;.001***0.29Persistence3.37 (±0.92)2.31 (±1.09)28.18&lt;.001***0.22 Wilks Lambda = 0.607,F(3,95) = 20.479 , p = &lt;.001\n\n\n\n\n\n\n\n\nWhen number of levels &gt;2\n\n\n\n\n\nWhen the categorical predictor has more than two levels, the function adds the solution of a multicomparison tukey post-hoc analyses to the table in letters. These letters are sorted based on the descriptives.\n\n\n\n\nlibrary(CaviR)\nmanovaR(data[,c('Groups','Autonomy','Vitality','Persistence')],\n        stand=TRUE, sign = 0.05, tukey = TRUE)\n\n\nvariables Group 1Group 2Group 3Group 4F-valuep-value eta-squaredAutonomy4.31 (±1.19) B4.23 (±0.95) B2.73 (±1.46) A2.16 (±1.16) A20.18&lt;.001***0.38Vitality4.23 (±1.02) B4.27 (±0.87) B2.69 (±1.40) A2.83 (±1.40) A13.72&lt;.001***0.30Persistence3.36 (±1.08) BC3.38 (±0.78) C2.64 (±1.15) AB1.96 (±0.93) A11.67&lt;.001***0.26 Wilks Lambda = 0.534,F(9,226.488) = 7.396 , p = &lt;.001\n\n\n\n\n\n\n\nReferences\n\nCohen, Jacob. 2013. Statistical Power Analysis for the Behavioral Sciences. Academic Press."
  },
  {
    "objectID": "DataRt.html",
    "href": "DataRt.html",
    "title": "Data Rt",
    "section": "",
    "text": "Get your dataset ready\n\n\nUpload, clean, restructure and save data\n\n\n\n\n\n\n\n\n\n\n\n\n\nWork with categorical variables\n\n\nCheck the role of categorical variables\n\n\n\n\n\n\n\n\n\n\n\n\n\nCo-Relate\n\n\nPerform correlation analyses\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression modelling\n\n\nPerform (multilevel) regression analyses\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck structural relationships\n\n\nTest structural (equation) models\n\n\n\n\n\n\n\n\n\n\n\n\n\nClusteRing\n\n\nPerform cluster analyses in R\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Literature.html",
    "href": "Literature.html",
    "title": "The package",
    "section": "",
    "text": "library(DT) # # datatable( # data, # escape=FALSE, # # class = ‘cell-border stripe’, # filter = ‘top’, # extensions = ‘Buttons’, # options = list( # pageLength = 20, # lengthMenu = c(10, 20, 50), # dom = ‘Bfrtip’, # autoWidth = TRUE, # buttons = c(‘copy’, ‘csv’, ‘excel’, ‘pdf’, ‘print’), # search = list(regex = TRUE, caseInsensitive = TRUE), # columnDefs = list( # list( # targets = 4, # render = JS( # “function(data, type, full, meta) {”, # ” if (type === ‘filter’) {“, #” return data.replace(/, /g, ‘|’);“, #” } else {“, #” return data;“, #” }“, #”}” # ) # ) # ) # ) # )"
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "Old Faithful",
    "section": "",
    "text": "Number of bins:"
  },
  {
    "objectID": "index.html#cavir-0.1",
    "href": "index.html#cavir-0.1",
    "title": "News",
    "section": "CaviR 0.1",
    "text": "CaviR 0.1\nIn December 2023, we built this website to include as much of the information available that has been developed under the label of CaviR. On this website, we now provide all tutorials that were available in DataRt and updated these with the development of CaviR as an R package.\nddd  dd  ddddd  dddddd  dddd  dd  dddd  dddd  dddd"
  },
  {
    "objectID": "Curriculum.html",
    "href": "Curriculum.html",
    "title": "Work with categorical variables",
    "section": "",
    "text": "Email: Joachim.waterschoot@ugent.be\n\nGithub\n\nLinkedIn\n\nResearchgate\n\nGoogle Scholar\n\n\nTO DO’S:\n\nMobility: (a) short-term visit or (b) longer-term mobility planned. Goals: to learn new techniques, transfer knowledge, establish/expand collaborations.\n\nTeach a course or mentor students: graduate or undergraduate?\n\nInvite and host a collaborator who will give a workshop in your lab.\n\n(Co-)organise a scientific meeting\n\nDevelop a database: specify if it is open-access or restricted\n\nPrepare publications in the popular press: name target magazines, radio programmes, etc. Mention relevant past experience.\n\nIssue Policy paper: name target organisations, explain what relationships will pave the way for conveying your research findings."
  },
  {
    "objectID": "Curriculum.html#publications",
    "href": "Curriculum.html#publications",
    "title": "Work with categorical variables",
    "section": "Publications",
    "text": "Publications\n\nBy year\n\n2023\n\n\n\n\n\n32. Waterschoot, J., Morbée, S., Soenens, B., Van den Bergh, O., Raemdonck, E., Brisbois, M., Schmitz, M., Klein, O., Luminet, O., Van Oost, P., Yzerbyt, V., & Vansteenkiste, M. (2023). **Psychological need fulfillment as a source of resilience: Its protective role in concerns and symptoms of anxiety and depression during the COVID-19 pandemic.** *Applied psychology. Health and well-being, 10*.1111/aphw.12508. Advance online publication. https://doi.org/10.1111/aphw.12508\n\n\n31. Waterschoot, J., Morbée, S., Van den Bergh, O., Yzerbyt, V., Raemdonck, E., Brisbois, M., Schmitz, M., Klein, O., Luminet, O., Van Oost, P., & Vansteenkiste, M. (2023). **How the Stringency of the COVID-19 Restrictions Influences Motivation for Adherence and Well-Being: The Critical Role of Proportionality.** *International Journal of Health Policy and Management, 12*(1), 1-13. doi: 10.34172/ijhpm.2023.8021\n\n\n30. Waterschoot, J., Van Oost, P., Vansteenkiste, M., Bribois, M., Schmitz, M., Morbée, S., Klein, O., Luminet, O., Van den Bergh, O., Raemdonck, E., & Yzerbyt, V. (2023) **Who is Motivated to Accept a Booster and Annual Dose? A Dimensional and Person-Centered Approach.** *Applied Psychology: Health and Well-Being, 15*(4), 1293-1318. https://doi.org/10.1111/aphw.12437\n\n\n29. Waterschoot, J., Yzerbyt, V., Soenens, B., Van den Bergh, O., Morbée, S., Schmitz, M., Van Oost, P., Luminet, O., Klein, O., & Vansteenkiste, M. (2023). **How do vaccination intentions change over time? The role of motivational growth.** *Health psychology, 42*(2), 113–123. https://doi.org/10.1037/hea0001228\n\n\n28. Vansteenkiste, M., Waterschoot, J., Morbée, S., Van Oost, P., Schmitz, M., Klein, O., Luminet, O., Yzerbyt, V., & Van den Bergh, O. (2023). **Psychologicalscience and its societal mission during the SARS-CoV-2 pandemic: The Motivation Barometeras an evidence-informed policy instrument in Belgium.** *Social Issues and Policy Review,* 1–30. https://doi.org/10.1111/sipr.12101\n\n\n27. Sypré, S., Waterschoot, J., Soenens, B., Verschueren, K., & Vansteenkiste, M. (2023). **Do Teachers Use Distinct Motivational Styles for Cognitively Gifted Learners? The Role of Effectiveness Beliefs, Fixed Mindset, and Misconceptions about Giftedness.** *European Journal of Psychology of Education,* 1-27. https://doi.org/10.1007/s10212-023-00716-2\n\n\n26. Morbée, S., Waterschoot, J., De Muynck, G. J., Haerens, L., Soenens, B., & Vansteenkiste, M. (2023). **Identifying profiles of parental (de) motivating behaviors in youth sports: A multi-informant approach.** *Motivation and Emotion, 47*(6), 990-1006. https://doi.org/10.1007/s11031-023-10040-3\n\n\n25. van der Kaap‐Deeder, J., Bülow, A., Waterschoot, J., Truyen, I., & Keijsers, L. (2022). **A moment of autonomy support brightens adolescents' mood: Autonomy support, psychological control and adolescent affect in everyday life.** *Child Development, early access.* http://doi.org/10.1111/cdev.13942\n\n\n24. Vermote, B., Morbée, S., Soenens, B., Vansteenkiste, M., Waterschoot, J., Beyers, W., & der Kaap-Deeder, V. (2023). **How do late adults experience meaning during the COVID-19 lockdown? The role of intrinsic goals.** *Journal of Happiness,* 1-22. https://doi.org/10.1007/s10902-023-00657-z\n\n\n23. Morbée, S., Haerens, L., Soenens, B., Loeys, T., De Clerck, T., Waterschoot, J., & Vansteenkiste, M. (2023). **Predictors and Outcomes of Sports Coaches’ Athlete-Invested Contingent Self-worth.** *Psychology of Sport and Exercise, 69,*102478. https://doi.org/10.1016/j.psychsport.2023.102478\n\n\n22. Desimpelaere, E., Soenens, B., Prinzie, P., Waterschoot, J., Vansteenkiste, M., Morbée, S., Schrooyen, C., & De Pauw, S. (2023). **Parents’ Stress, Parental Burnout, and Parenting Behavior during the COVID-19 Pandemic: Comparing Parents of Children with and without Complex Care Needs.** *Journal of Child Family Studies, 32*, 3681–3696. https://doi.org/10.1007/s10826-023-02702-0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;  –&gt;  –&gt;  –&gt;  –&gt;  –&gt;  –&gt;  –&gt;  –&gt;\n\n–&gt;  –&gt;  –&gt;  –&gt;  –&gt;\n\n–&gt;\n\n–&gt;  –&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latest News",
    "section": "",
    "text": "Latest News\n\n\n\n\n\n\n\n\n\n\nGet your dataset ready\n\n\nUpload, clean, restructure and save data\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWork with categorical variables\n\n\nCheck the role of categorical variables\n\n\n\nDec 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCo-Relate\n\n\nPerform correlation analyses\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression modelling\n\n\nPerform (multilevel) regression analyses\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n\nRead more…\n\n\n\nThemes\n\n\n\n\n\n\n\n\n\n\nMotivation and risk perception\n\n\nQuality of motiavtion, lack of motivation and risk perception\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental health\n\n\nConcern, basic psychological needs and vulnerable groups\n\n\n\n\n\n\n\n\n\n\n\n\n\nContextual predictors\n\n\nHospitalization load and stringency, COVID-19 certificate, communication style and trust\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nThe Motivation Barometer\n\nSymposium: policy meets science  June 7th, 2022 \n\n\n\n\n\n\nhey hallow"
  },
  {
    "objectID": "reports.html",
    "href": "reports.html",
    "title": "Public reports",
    "section": "",
    "text": "New names:\n• `File` -&gt; `File...3`\n• `File` -&gt; `File...4`"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Scientific publications",
    "section": "",
    "text": "AllMotivationTrust and CommunicationRisk PerceptionVaccinationWell-beingTheory and practice"
  },
  {
    "objectID": "publications.html#first",
    "href": "publications.html#first",
    "title": "Scientific publications",
    "section": "",
    "text": "A first section"
  },
  {
    "objectID": "publications.html#second",
    "href": "publications.html#second",
    "title": "Scientific publications",
    "section": "",
    "text": "content of sub-chapter #2"
  },
  {
    "objectID": "publications.html#third",
    "href": "publications.html#third",
    "title": "Scientific publications",
    "section": "",
    "text": "content of sub-chapter #3"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Latest News",
    "section": "",
    "text": "howlt :::\n::: heyla :::\n:::\n\n\n\n\n\nxxx\n\nhey hallow\n\n\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]"
  },
  {
    "objectID": "index.html#podcast",
    "href": "index.html#podcast",
    "title": "Latest News",
    "section": "Podcast ",
    "text": "Podcast \n\nNederlandsFrenchEnglish"
  },
  {
    "objectID": "themes/Motivation.html",
    "href": "themes/Motivation.html",
    "title": "Motivation and risk perception",
    "section": "",
    "text": "What about?\n\nQuality of motivation\ndsdsds\n\n\nLack of motivation\ndsdsds\n\n\nRisk perception\ndsdsds\n\n\n\nPodcast\n\nMotivationRisk perception\n\n\n\nNederlandsFrenchEnglish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNederlandsFrenchEnglish"
  },
  {
    "objectID": "themes/Motivation.html#key-questions",
    "href": "themes/Motivation.html#key-questions",
    "title": "Motivation",
    "section": "",
    "text": "What is the role of motivation?\n\nDid stricter measures result in demotivation?\n\nWhat background factors played an important role in the overall motivation?\n\nWhat can we learn from this?"
  },
  {
    "objectID": "themes/Motivation.html#podcast",
    "href": "themes/Motivation.html#podcast",
    "title": "Motivation",
    "section": "Podcast",
    "text": "Podcast\n\nNederlandsFrenchEnglish"
  },
  {
    "objectID": "themes/Wellbeing.html",
    "href": "themes/Wellbeing.html",
    "title": "Mental health",
    "section": "",
    "text": "What about?\n\nConcerns\ndsdsds\n\n\nBasic psychological needs\ndsdsds\n\n\nVulnerable groups\ndsdsds\n\n\n\nPodcast\n\nNederlandsFrenchEnglish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRisk perception\n\nNederlandsFrenchEnglish"
  },
  {
    "objectID": "themes/Contextual.html",
    "href": "themes/Contextual.html",
    "title": "Contextual predictors",
    "section": "",
    "text": "What about?\n\nHospitalization load and stringency\ndsdsds\n\n\nCOVID-19 certificate\ndsdsds\n\n\nCommunication style\ndsdsds\n\n\nTrust\ndsdsds\n\n\n\nPodcast\n\nNederlandsFrenchEnglish"
  }
]